"""
Lab 9: Continuous Validation and Uncertainty Quantification
============================================================

Demonstrates two critical aspects of maintaining a "living" Digital Twin:

Part 1: Automated Parameter Recalibration
    - Digital Twin starts with incorrect parameter value
    - Uses PI controller to automatically learn correct value from real data
    - Shows convergence of model parameters to ground truth

Part 2: Uncertainty Quantification with Monte Carlo
    - Predicts future system behavior with uncertain inputs
    - Uses Monte Carlo simulation to generate probability distribution
    - Provides confidence intervals for risk-informed decision making

Prerequisites:
    - numpy
    - pandas
    - scipy
    - matplotlib
    - ground_truth.csv file (generated by generate_ground_truth.py)

Usage:
    python continuous_validation_and_uq.py
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.integrate import solve_ivp
import os


# ========================================================================================
# MOTOR PARAMETERS (TRUE VALUES)
# ========================================================================================

# These are the "true" physical constants used to generate ground truth data
TRUE_PARAMS = {
    # Electrical parameters
    'R': 1.0,           # Armature resistance (Ω)
    'L': 0.5,           # Armature inductance (H)
    'L_e': 0.01,        # Back-EMF constant (V·s/rad)

    # Mechanical parameters
    'J': 0.01,          # Rotor inertia (kg·m²)
    'b': 0.1,           # Viscous friction (N·m·s/rad) - THIS WILL BE "LEARNED"
    'K_t': 0.01,        # Torque constant (N·m/A)

    # Thermal parameters (for uncertainty quantification)
    'C_th': 50.0,       # Thermal capacitance (J/°C)
    'R_th': 2.0,        # Thermal resistance (°C/W)
    'T_ambient': 25.0,  # Ambient temperature (°C)
}

# PI Controller Gains for Parameter Recalibration
KP = 0.05  # Proportional gain - responds to current error
KI = 0.2   # Integral gain - eliminates steady-state bias


# ========================================================================================
# DC MOTOR MODEL WITH THERMAL DYNAMICS
# ========================================================================================

def dc_motor_model_with_thermal(t, y, voltage_func, params):
    """
    Complete DC motor model including thermal dynamics.

    This extends the electrical-mechanical model from Lab 5 with temperature.

    State vector y = [angular_velocity, current, temperature]

    Args:
        t: Current time
        y: State vector [omega, i, T]
        voltage_func: Function returning voltage at time t
        params: Dictionary of motor parameters

    Returns:
        derivatives: [d_omega/dt, di/dt, dT/dt]
    """
    omega, i, T = y
    V = voltage_func(t)

    # Extract parameters
    R = params['R']
    L = params['L']
    L_e = params['L_e']
    J = params['J']
    b = params['b']
    K_t = params['K_t']
    C_th = params['C_th']
    R_th = params['R_th']
    T_ambient = params['T_ambient']

    # Electrical dynamics: di/dt = (V - R*i - L_e*ω) / L
    di_dt = (V - R*i - L_e*omega) / L

    # Mechanical dynamics: dω/dt = (K_t*i - b*ω) / J
    domega_dt = (K_t*i - b*omega) / J

    # Thermal dynamics: dT/dt = (P_heat - Q_cool) / C_th
    # Heat generation from electrical resistance
    P_heat = R * i**2

    # Heat dissipation to ambient
    Q_cool = (T - T_ambient) / R_th

    # Temperature rate of change
    dT_dt = (P_heat - Q_cool) / C_th

    return [domega_dt, di_dt, dT_dt]


def dc_motor_model_mechanical_only(t, y, voltage_func, params):
    """
    Simplified DC motor model for recalibration (mechanical dynamics only).

    Used for fast single-step predictions in Part 1.

    State vector y = [angular_velocity, current]

    Args:
        t: Current time
        y: State vector [omega, i]
        voltage_func: Function returning voltage at time t
        params: Dictionary of motor parameters

    Returns:
        derivatives: [d_omega/dt, di/dt]
    """
    omega, i = y
    V = voltage_func(t)

    # Extract parameters
    R = params['R']
    L = params['L']
    L_e = params['L_e']
    J = params['J']
    b = params['b']  # This is the parameter we'll be estimating
    K_t = params['K_t']

    # Electrical dynamics
    di_dt = (V - R*i - L_e*omega) / L

    # Mechanical dynamics
    domega_dt = (K_t*i - b*omega) / J

    return [domega_dt, di_dt]


# ========================================================================================
# PART 1: REAL-TIME PARAMETER RECALIBRATION
# ========================================================================================

def run_recalibration_simulation():
    """
    Demonstrates automated parameter recalibration using PI controller.

    The Digital Twin starts with an incorrect friction parameter (b) and
    automatically learns the correct value by comparing its predictions
    to real sensor data.

    This simulates a "living" Digital Twin that adapts to model drift
    or changes in the physical asset over time.
    """
    print("\n" + "="*70)
    print("PART 1: AUTOMATED PARAMETER RECALIBRATION")
    print("="*70)

    # Load ground truth data
    if not os.path.exists('ground_truth.csv'):
        print("\n✗ Error: ground_truth.csv not found!")
        print("  Please run 'python generate_ground_truth.py' first.")
        return

    df = pd.read_csv('ground_truth.csv')
    print(f"\n✓ Loaded ground truth data: {len(df)} samples")

    # True parameter value (what we're trying to learn)
    b_true = TRUE_PARAMS['b']

    # Initialize Digital Twin with INCORRECT parameter (simulating model drift)
    b_estimated = b_true * 1.5  # 50% too high!
    print(f"\n  True friction parameter:      b = {b_true:.4f}")
    print(f"  Initial (wrong) estimate:     b = {b_estimated:.4f}")
    print(f"  Initial error:                {((b_estimated/b_true - 1)*100):.1f}%")

    # PI controller state
    integral_error = 0.0

    # History tracking
    b_history = []
    error_history = []
    time_history = []

    # Current state of the Digital Twin
    omega_estimated = 0.0
    i_estimated = 0.0

    # Create a copy of parameters for the Digital Twin
    twin_params = TRUE_PARAMS.copy()

    print("\nRunning recalibration simulation...")

    # Iterate through ground truth data
    for idx in range(len(df) - 1):
        # Get current and next time steps
        t_current = df.loc[idx, 'time']
        t_next = df.loc[idx + 1, 'time']
        dt = t_next - t_current

        # Real sensor measurements (current time step)
        real_voltage = df.loc[idx, 'voltage']
        real_velocity_current = df.loc[idx, 'angular_velocity']
        real_current = df.loc[idx, 'current']

        # Real sensor measurements (next time step for derivative calculation)
        real_velocity_next = df.loc[idx + 1, 'angular_velocity']

        # PREDICT: Use Digital Twin's model to predict next velocity
        # Update twin parameters with current estimate
        twin_params['b'] = b_estimated

        # Use MEASURED state as starting point (sensor fusion)
        # This prevents accumulation of model errors
        omega_measured = real_velocity_current
        i_measured = real_current

        # Create voltage function
        voltage_func = lambda t: real_voltage

        # Calculate what the model PREDICTS the derivatives should be
        state = [omega_measured, i_measured]
        derivatives = dc_motor_model_mechanical_only(t_current, state, voltage_func, twin_params)
        predicted_domega_dt = derivatives[0]

        # Predict next velocity using model
        omega_predicted = omega_measured + predicted_domega_dt * dt

        # COMPARE: What was the ACTUAL change in velocity?
        # Observed derivative from real sensor data
        observed_domega_dt = (real_velocity_next - real_velocity_current) / dt

        # Error in the DERIVATIVE (this isolates parameter error)
        derivative_error = observed_domega_dt - predicted_domega_dt

        # UPDATE INTEGRAL ERROR
        integral_error += derivative_error * dt

        # RECALIBRATE: PI controller adjusts parameter
        # Larger derivative error means b is too high (more damping than reality)
        b_adjustment = -(KP * derivative_error + KI * integral_error) * dt
        b_estimated += b_adjustment

        # Prevent parameter from going negative or too large
        b_estimated = max(0.001, min(1.0, b_estimated))

        # For visualization, also calculate prediction error in velocity
        velocity_error = real_velocity_next - omega_predicted

        # Record history
        time_history.append(t_current)
        b_history.append(b_estimated)
        error_history.append(velocity_error)

    # Final results
    final_error_pct = ((b_estimated / b_true - 1) * 100)
    print(f"\n✓ Recalibration complete!")
    print(f"\n  Final parameter estimate:     b = {b_estimated:.4f}")
    print(f"  True value:                   b = {b_true:.4f}")
    print(f"  Final error:                  {abs(final_error_pct):.2f}%")

    # Visualization
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

    # Plot 1: Prediction Error Over Time
    ax1.plot(time_history, error_history, 'b-', linewidth=1.5, alpha=0.7)
    ax1.axhline(y=0, color='k', linestyle='--', linewidth=1, alpha=0.5)
    ax1.set_xlabel('Time (s)', fontsize=11)
    ax1.set_ylabel('Prediction Error (rad/s)', fontsize=11)
    ax1.set_title('Model Prediction Error: Driven to Zero by PI Controller',
                  fontsize=12, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.text(0.02, 0.98,
             'Initially large error due to wrong parameter\n'
             'PI controller drives error toward zero',
             transform=ax1.transAxes, fontsize=9,
             verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    # Plot 2: Parameter Convergence
    ax2.plot(time_history, b_history, 'g-', linewidth=2, label='Estimated b')
    ax2.axhline(y=b_true, color='r', linestyle='--', linewidth=2,
                label=f'True b = {b_true:.3f}')
    ax2.set_xlabel('Time (s)', fontsize=11)
    ax2.set_ylabel('Friction Parameter b', fontsize=11)
    ax2.set_title('Parameter Convergence: Digital Twin "Learns" Correct Value',
                  fontsize=12, fontweight='bold')
    ax2.legend(fontsize=10)
    ax2.grid(True, alpha=0.3)
    ax2.text(0.02, 0.98,
             f'Initial: b = {b_true * 1.5:.3f} (50% wrong)\n'
             f'Final:   b = {b_estimated:.3f} ({abs(final_error_pct):.1f}% error)\n'
             f'Converged through continuous validation',
             transform=ax2.transAxes, fontsize=9,
             verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))

    plt.tight_layout()
    plt.savefig('recalibration_results.png', dpi=150, bbox_inches='tight')
    print(f"\n✓ Saved visualization to recalibration_results.png")

    return fig


# ========================================================================================
# PART 2: UNCERTAINTY QUANTIFICATION WITH MONTE CARLO
# ========================================================================================

def run_monte_carlo_uq():
    """
    Demonstrates uncertainty quantification for Digital Twin predictions.

    Uses Monte Carlo simulation to predict peak motor temperature with
    uncertain input voltage. Generates probability distribution and
    confidence intervals for risk-informed decision making.

    This answers: "What's the worst-case temperature we might see,
    and how confident are we in that prediction?"
    """
    print("\n" + "="*70)
    print("PART 2: UNCERTAINTY QUANTIFICATION WITH MONTE CARLO")
    print("="*70)

    # Scenario: Predict peak temperature for a future operational cycle
    N_RUNS = 500  # Number of Monte Carlo samples
    print(f"\n  Monte Carlo runs: {N_RUNS}")

    # Future input uncertainty: Voltage will be 12V ± 0.5V
    MEAN_VOLTAGE = 12.0  # V
    VOLTAGE_STD_DEV = 0.5  # V (1 sigma)
    print(f"  Input uncertainty: {MEAN_VOLTAGE}V ± {VOLTAGE_STD_DEV}V (1σ)")

    # Simulation parameters
    t_start = 0.0
    t_end = 30.0  # 30 second operational cycle
    dt = 0.05
    time_points = np.arange(t_start, t_end + dt, dt)

    print(f"  Simulation duration: {t_end} seconds")
    print(f"\nRunning {N_RUNS} Monte Carlo simulations...")

    # Store results
    peak_temperatures = []

    # Progress indicator
    progress_points = [int(N_RUNS * p) for p in [0.25, 0.5, 0.75, 1.0]]

    for run in range(N_RUNS):
        # Generate unique, uncertain voltage profile for this run
        # Each run samples from the input distribution
        voltage_noise = np.random.normal(0, VOLTAGE_STD_DEV, size=len(time_points))
        voltage_profile = MEAN_VOLTAGE + voltage_noise

        # Create voltage function for this specific run
        voltage_func = lambda t: np.interp(t, time_points, voltage_profile)

        # Initial conditions: motor at rest, ambient temperature
        omega_0 = 0.0  # rad/s
        i_0 = 0.0      # A
        T_0 = TRUE_PARAMS['T_ambient']  # °C
        y0 = [omega_0, i_0, T_0]

        # Run full ODE simulation with this voltage profile
        # Use TRUE parameters (this is a prediction, not calibration)
        solution = solve_ivp(
            fun=lambda t, y: dc_motor_model_with_thermal(t, y, voltage_func, TRUE_PARAMS),
            t_span=(t_start, t_end),
            y0=y0,
            t_eval=time_points,
            method='RK45',
            max_step=dt
        )

        if not solution.success:
            print(f"  Warning: Run {run} failed")
            continue

        # Extract temperature trajectory
        temperature = solution.y[2]

        # Record peak temperature for this run
        peak_temp = np.max(temperature)
        peak_temperatures.append(peak_temp)

        # Progress indicator
        if (run + 1) in progress_points:
            pct = int((run + 1) / N_RUNS * 100)
            print(f"  Progress: {pct}% complete ({run + 1}/{N_RUNS} runs)")

    # Convert to numpy array for analysis
    peak_temperatures = np.array(peak_temperatures)

    print(f"\n✓ Monte Carlo simulation complete!")

    # Statistical analysis
    mean_peak = np.mean(peak_temperatures)
    std_peak = np.std(peak_temperatures)
    min_peak = np.min(peak_temperatures)
    max_peak = np.max(peak_temperatures)

    # Calculate 90% confidence interval (5th to 95th percentile)
    lower_bound = np.percentile(peak_temperatures, 5)
    upper_bound = np.percentile(peak_temperatures, 95)

    print(f"\n{'='*70}")
    print("UNCERTAINTY QUANTIFICATION RESULTS")
    print(f"{'='*70}")
    print(f"\nPeak Temperature Distribution:")
    print(f"  Mean:             {mean_peak:.2f}°C")
    print(f"  Std Dev:          {std_peak:.2f}°C")
    print(f"  Range:            [{min_peak:.2f}, {max_peak:.2f}]°C")
    print(f"\n90% Confidence Interval:")
    print(f"  We are 90% confident the peak temperature will be")
    print(f"  between {lower_bound:.2f}°C and {upper_bound:.2f}°C")
    print(f"\nRisk Assessment:")
    if upper_bound > 100:
        print(f"  ⚠ WARNING: Upper bound exceeds 100°C safety limit!")
        print(f"  Recommend reducing voltage or adding cooling.")
    else:
        print(f"  ✓ Peak temperature stays within safe limits")
    print(f"{'='*70}")

    # Visualization
    fig, ax = plt.subplots(figsize=(10, 6))

    # Histogram
    n, bins, patches = ax.hist(peak_temperatures, bins=30, density=True,
                                alpha=0.7, color='skyblue', edgecolor='black')

    # Mark mean and confidence interval
    ax.axvline(mean_peak, color='green', linestyle='--', linewidth=2,
               label=f'Mean: {mean_peak:.1f}°C')
    ax.axvline(lower_bound, color='red', linestyle='--', linewidth=2,
               label=f'5th percentile: {lower_bound:.1f}°C')
    ax.axvline(upper_bound, color='red', linestyle='--', linewidth=2,
               label=f'95th percentile: {upper_bound:.1f}°C')

    # Shade 90% confidence region
    ax.axvspan(lower_bound, upper_bound, alpha=0.2, color='red',
               label='90% Confidence Interval')

    ax.set_xlabel('Peak Temperature (°C)', fontsize=12)
    ax.set_ylabel('Probability Density', fontsize=12)
    ax.set_title('Uncertainty Quantification: Distribution of Predicted Peak Temperatures\n'
                 f'Input: Voltage = {MEAN_VOLTAGE}V ± {VOLTAGE_STD_DEV}V | '
                 f'{N_RUNS} Monte Carlo Samples',
                 fontsize=13, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3, axis='y')

    # Add text box with interpretation
    textstr = (f'Mean ± σ: {mean_peak:.1f} ± {std_peak:.1f}°C\n'
               f'90% CI: [{lower_bound:.1f}, {upper_bound:.1f}]°C\n\n'
               f'Interpretation:\n'
               f'• 90% of outcomes fall in shaded region\n'
               f'• 5% chance peak > {upper_bound:.1f}°C\n'
               f'• 5% chance peak < {lower_bound:.1f}°C')

    ax.text(0.98, 0.97, textstr,
            transform=ax.transAxes, fontsize=9,
            verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

    plt.tight_layout()
    plt.savefig('uncertainty_quantification_results.png', dpi=150, bbox_inches='tight')
    print(f"\n✓ Saved visualization to uncertainty_quantification_results.png\n")

    return fig


# ========================================================================================
# GROUND TRUTH DATA GENERATOR (HELPER FUNCTION)
# ========================================================================================

def generate_ground_truth_if_needed():
    """
    Generate ground truth data if it doesn't exist.

    This creates a CSV file with motor behavior under a known voltage profile.
    """
    if os.path.exists('ground_truth.csv'):
        return  # Already exists

    print("\n" + "="*70)
    print("GENERATING GROUND TRUTH DATA")
    print("="*70)
    print("\nground_truth.csv not found. Generating now...")

    # Simulation parameters
    t_start = 0.0
    t_end = 12.0
    dt = 0.05
    time_points = np.arange(t_start, t_end + dt, dt)

    # Voltage profile: steps and ramps
    def voltage_profile(t):
        if t < 2.0:
            return 5.0
        elif t < 4.0:
            return 12.0
        elif t < 6.0:
            return 8.0
        elif t < 8.0:
            # Ramp from 8V to 15V
            return 8.0 + (15.0 - 8.0) * (t - 6.0) / 2.0
        elif t < 10.0:
            return 15.0
        else:
            # Ramp from 15V to 0V
            return 15.0 - 15.0 * (t - 10.0) / 2.0

    # Initial conditions
    omega_0 = 0.0
    i_0 = 0.0
    y0 = [omega_0, i_0]

    # Solve ODE
    solution = solve_ivp(
        fun=lambda t, y: dc_motor_model_mechanical_only(t, y, voltage_profile, TRUE_PARAMS),
        t_span=(t_start, t_end),
        y0=y0,
        t_eval=time_points,
        method='RK45',
        max_step=dt
    )

    # Create DataFrame
    df = pd.DataFrame({
        'time': solution.t,
        'voltage': [voltage_profile(t) for t in solution.t],
        'angular_velocity': solution.y[0],
        'current': solution.y[1]
    })

    # Save to CSV
    df.to_csv('ground_truth.csv', index=False)
    print(f"\n✓ Generated ground_truth.csv with {len(df)} samples")
    print("="*70)


# ========================================================================================
# MAIN EXECUTION
# ========================================================================================

def main():
    """
    Main function: Run both parts of the lab.
    """
    print("\n" + "="*70)
    print("LAB 9: CONTINUOUS VALIDATION & UNCERTAINTY QUANTIFICATION")
    print("="*70)
    print("\nDemonstrating:")
    print("  1. Automated parameter recalibration (PI controller)")
    print("  2. Uncertainty quantification (Monte Carlo simulation)")

    # Ensure ground truth data exists
    generate_ground_truth_if_needed()

    # Part 1: Parameter Recalibration
    fig1 = run_recalibration_simulation()

    # Part 2: Uncertainty Quantification
    fig2 = run_monte_carlo_uq()

    # Show all plots
    plt.show()

    print("="*70)
    print("LAB 9 COMPLETE")
    print("="*70)
    print("\nKey Takeaways:")
    print("  • Digital Twins can self-calibrate using PI control")
    print("  • Monte Carlo provides confidence intervals for predictions")
    print("  • Uncertainty quantification enables risk-informed decisions")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
